---
title: "Intro to Bayes"
author: "Daniel Anderson "
date: "Week 7"
output:
  xaringan::moon_reader:
    css: ["default", "new.css"]
    lib_dir: libs
    nature:
      navigation:
        scroll: false
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "https://platform.twitter.com/widgets.js"
    includes:
      in_header: "load-feather.html"
---

```{r include = FALSE}
source(here::here("static", "slides", "slide-setup.R"))
xaringanExtra::use_clipboard()
library(tidyverse)
theme_set(theme_minimal(25))
knitr::opts_chunk$set(fig.width = 13, message = FALSE)
update_geom_defaults('path', list(size = 2))
update_geom_defaults('point', list(size = 5))
update_geom_defaults('text', list(size = 9))
```

`r setup("w7p1")`

---
# Agenda

.gray[[We're not going to get through it all]]

* Review Homework 2

* Some equation practice

* Introduce Bayes theorem

  + Go through an example with estimating a mean

* Discuss Bayes in the context of regression modeling


---
class: inverse-red middle
# Homework 2 Review

---
class: inverse-red middle
# Equation practice

---
# The data
From an example in the Mplus manual. I made up the column names. 

`r countdown::countdown(1, seconds = 30)`

```{r }
mplus_d <- read_csv(here::here("data", "mplus920.csv"))
mplus_d
```


---
# Model 1
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
library(lme4)
library(equatiomatic)

m1 <- lmer(score ~ 1 + (1|distid),
           data = mplus_d)

extract_eq(m1)
```


--
```{r eval = FALSE}
lmer(score ~ 1 + (1|distid), data = mplus_d)
```

---
# Model 2
### Fit the following model

`r countdown::countdown(1)`

```{r echo = FALSE, message = FALSE}
m2 <- lmer(score ~ baseline + (1|schid) + (1|distid),
           data = mplus_d)

extract_eq(m2)
```


--
```{r eval = FALSE}
lmer(score ~ baseline + (1|schid) + (1|distid),
     data = mplus_d)
```

---
# Model 3
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m3 <- lmer(score ~ baseline * dist_ses + (baseline|schid) + (1|distid),
           data = mplus_d)

extract_eq(m3)
```


--
```{r eval = FALSE}
lmer(score ~ baseline * dist_ses + 
       (baseline|schid) + (1|distid),
     data = mplus_d)
```

---
# Model 4
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m4 <- lmer(score ~ baseline + sch_treatment + dist_ses + 
             (baseline|schid) + (1|distid),
           data = mplus_d)

extract_eq(m4)
```


--
```{r eval = FALSE}
lmer(score ~ baseline + sch_treatment + dist_ses + 
       (baseline|schid) + (1|distid),
     data = mplus_d)
```


---
# Model 5
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m5 <- lmer(score ~ baseline * sch_treatment + dist_ses + 
             (baseline|schid) + (sch_treatment|distid),
           data = mplus_d)

extract_eq(m5)
```


--
```{r eval = FALSE}
lmer(score ~ baseline * sch_treatment + dist_ses + 
       (baseline|schid) + (sch_treatment|distid),
     data = mplus_d)
```


---
# Model 6
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m6 <- lmer(score ~ baseline * sch_treatment + dist_ses + 
             (baseline|schid) + (baseline * sch_treatment||distid),
           data = mplus_d)

extract_eq(m6, font_size = "small")
```


--
```{r eval = FALSE}
lmer(score ~ baseline * sch_treatment + dist_ses + 
       (baseline|schid) + 
       (baseline * sch_treatment||distid),
           data = mplus_d)
```


---
# Final one
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m7 <- lmer(score ~ baseline * sch_treatment * dist_ses + 
             (baseline|schid) + (baseline |distid),
           data = mplus_d)

extract_eq(m7, font_size = "scriptsize")
```


--
```{r eval = FALSE}
lmer(score ~ baseline * sch_treatment * dist_ses + 
             (baseline|schid) + (baseline |distid),
           data = mplus_d)
```


---
class: inverse-blue middle
# Bayes



---
# A disclaimer
* There is **no** chance we'll really be able to do Bayes justice in this class

* The hope for today is that you'll get an introduction

* By the end you should be able to fit the models you already can, but in a Bayes framework

* Hopefully you also recognize the tradeoffs, and potential extensions

---
class: inverse-red middle
# Bayes theorem

---
# In equation form
You'll see this presented many different ways, perhaps mostly commonly as

$$
p(B \mid A) = \frac{ p(A \mid B) \times p(B)}{p(A)}
$$
where $\mid$ is read as "given" and $p$ is the probability

--

I prefer to give $A$ and $B$ more meaningful names

--

$$
p(\text{prior} \mid \text{data}) = \frac{ p(\text{data} \mid \text{prior}) \times p(\text{prior})}{\text{data}}
$$

---
# A real example
Classifying a student with a learning disability. We want to know 

$$
p(\text{LD} \mid \text{Test}_p) = \frac{ p(\text{Test}_p \mid \text{LD}) \times p(\text{LD})}{\text{Test}_p}
$$
--
Notice, this means we need to know:

--

* True positive rate of the test, $p(\text{Test}_p \mid \text{LD})$


--

* Base rate for learning disabilities, $p(\text{LD})$


--
* Base rate for testing positive, $\text{Test}_p$

---
# Estimating
If we have these things, we can estimate the probability that a student has a learning disability, given a positive test.


--
## Let's assume: 
* $p(\text{Test}_p \mid \text{LD}) = 0.90$

* $p(\text{LD}) = 0.10$

* $\text{Test}_p = 0.20$

---

$$
p(\text{LD} \mid \text{Test}_p) = \frac{ .90 \times .10}{.20}
$$


--
$$
p(\text{LD} \mid \text{Test}_p) = 0.45
$$


--
A bit less than you might have expected? Probability is hard...


--
When we see things like "90% true positive rate" we want to interpret it as $p(\text{LD} \mid \text{Test}_p)$, when it's actually $p(\text{Test}_p \mid \text{LD})$

---
# Pieces
If we know all the pieces, we can estimate Bayes theorem directly. 


--
![](https://media2.giphy.com/media/2ZVrNVOtaM2q1zluYs/giphy.gif)

Unfortunately this is almost never the case...

---
# Alternative view

$$
\text{updated beliefs} = \frac{\text{likelihood of data} \times \text{prior information}}{\text{average likelihood}}
$$

--
How do we calculate the likelihood of the data? We have to assume some distribution.

---
# Example with IQ

.footnote[This example borrowed from [TJ Mahr](https://cdn.rawgit.com/tjmahr/Psych710_BayesLecture/55f446a0/bayes_slides.html)]

```{r }
#install.packages("carData")
iqs <- carData::Burt$IQbio
iqs
```

--
IQ scores are generally assumed to be generated from a distribution that looks like this:

$$
IQ_i \sim N(100, 15)
$$

--
```{r echo = FALSE, fig.height = 3}
ggplot(data.frame(x = c(60, 140)), aes(x)) +
  stat_function(fun = ~dnorm(., 100, 15))
```

---
# Likelihood
What's the likelihood of a score of 80, assuming this distribution?

--
```{r echo = FALSE, fig.height = 6}
ggplot(data.frame(x = c(60, 140)), aes(x)) +
  stat_function(fun = ~dnorm(., 100, 15)) +
  geom_point(aes(y = y),
             data.frame(x = 80, y = dnorm(80, 100, 15)),
             color = "magenta") +
  geom_segment(x = 80, xend = 80, y = 0, yend = dnorm(80, 100, 15),
               linetype = "dashed",
               color = "magenta") +
  geom_segment(x = -Inf, xend = 80, 
               y = dnorm(80, 100, 15), yend = dnorm(80, 100, 15),
               linetype = "dashed",
               color = "magenta")
```

--

```{r }
dnorm(80, mean = 100, sd = 15)
```

---
# Likelihood of the data
We sum the likelihood to get the overall likelihood of the data. However, this leads to very small numbers. Computationally, it's easier to sum the *log* of these likelihoods.

--
```{r }
dnorm(iqs, mean = 100, sd = 15, log = TRUE)
```

--
```{r }
sum(dnorm(iqs, mean = 100, sd = 15, log = TRUE))
```

---
# Alternative distributions

What if we assumed the data were generated from an alternative distribution, say $IQ_i \sim N(115, 5)$?

--
```{r }
sum(dnorm(iqs, mean = 115, sd = 5, log = TRUE))
```

--
The value is *much* lower. In most models, we are estimating $\mu$ and $\sigma$, and trying to find values that *maximize* the sum of the log likelihoods.

---
# Visually

The real data generating distribution

```{r echo = FALSE}
iq_likelihood <- data.frame(x = iqs, y = dnorm(iqs, 100, 15))

ggplot(data.frame(x = c(60, 140)), aes(x)) +
  stat_function(fun = ~dnorm(., 100, 15)) +
  geom_point(aes(y = y),
             iq_likelihood,
             color = "magenta") +
  geom_segment(aes(x = x, xend = x, y = 0, yend = y),
               iq_likelihood,
               linetype = "dashed",
               color = "magenta")
```

---
# Visually

The poorly fitting one

```{r echo = FALSE}
iq_likelihood2 <- data.frame(x = iqs, y = dnorm(iqs, 120, 5))

ggplot(data.frame(x = c(60, 140)), aes(x)) +
  stat_function(fun = ~dnorm(., 120, 5)) +
  geom_point(aes(y = y),
             iq_likelihood2,
             color = "magenta") +
  geom_segment(aes(x = x, xend = x, y = 0, yend = y),
               iq_likelihood2,
               linetype = "dashed",
               color = "magenta")
```

---
# Non-Bayesian
In a frequentist regression model, we would find parameters that *maximize* the likelihood. Note - the distributional mean is often conditional.


--
This is part of why I've come to prefer notation that emphasizes the data generating process. 

---
# Example
I know we've talked about this before, but a simple linear regression model like this

```{r }
m <- lm(IQbio ~ class, data = carData::Burt)
```

--
is generally displayed like this


```{r echo = FALSE}
equatiomatic::extract_eq(m, font_size = "normalsize")
```


--
But we could display the same thing like this
$$
\begin{align}
\operatorname{IQbio} &\sim N(\widehat{\mu}, \widehat{\sigma}) \\
\widehat{\mu} = \alpha &+ \beta_{1}(\operatorname{class}_{\operatorname{low}}) + \beta_{2}(\operatorname{class}_{\operatorname{medium}})
\end{align}
$$

---
class: inverse-red middle

# Priors

---
# Bayesian posterior

$$
\text{posterior} = \frac{ \text{likelihood} \times \text{prior}}{\text{average likelihood}}
$$


--
The above is how we estimate with Bayes. 


--
In words, it states that our updated beliefs (posterior) depend on the evidence from our data (likelihood) and our prior knowledge/conceptions/information (prior).


--
Our prior will shift in accordance with the evidence from the data

---
# Basic example
Let's walk through a basic example where we're just estimating a mean. We'll assume we somehow magically know the variance. Please follow along.


--
First, generate some data

```{r }
set.seed(123)
true_data <- rnorm(50, 5, 1)
```

---
# Grid search
We're now going to specify a grid of possible means for our data. Let's search anywhere from -3 to 12 in 0.1 intervals.

--
```{r }
grid <- tibble(possible_mean = seq(-3, 12, 0.1))
```

--

Next, we'll specify a *prior distribution*. That is - how likely do we *think* each of these possible means are?


--
Let's say our best guess is $\mu = 2$. Values on either side of $2$ should be less likely.  

--
```{r }
prior <- dnorm(grid$possible_mean, mean = 2, sd = 1)
```

---
# Plot our prior

```{r }
grid %>% 
  mutate(prior = prior) %>% 
  ggplot(aes(possible_mean, prior)) +
  geom_line()
```

Note that the *strength* of our prior depends on the standard deviation

This would be our best guess as to where the data would fall *before* observing the data.

---
# Look at other priors

```{r fig.height = 6}
grid %>% 
  mutate(prior1 = dnorm(possible_mean, mean = 2, sd = 1),
         prior2 = dnorm(possible_mean, mean = 2, sd = 2),
         prior3 = dnorm(possible_mean, mean = 2, sd = 3)) %>% 
  ggplot(aes(possible_mean)) +
  geom_line(aes(y = prior1)) + 
  geom_line(aes(y = prior2), color = "cornflowerblue") + 
  geom_line(aes(y = prior3), color = "firebrick")  
```

---
# Set prior
* Let's go with a fairly conservative prior, with $\mu = 2, \sigma = 3$.

* We also need to normalize it so the probability sums to 1.0

--
```{r }
grid <- grid %>% 
  mutate(prior = dnorm(possible_mean, mean = 2, sd = 3),
         prior = prior / sum(prior)) # normalize
```


---
# Observe 1 data point
```{r }
grid <- grid %>% 
  mutate(likelihood = dnorm(true_data[1], possible_mean, 2))
grid
```

---
# Compute posterior

```{r }
grid <- grid %>% 
  mutate(posterior = likelihood * prior,
         posterior = posterior / sum(posterior)) # normalize
```

---
# Plot

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```


---
# Observe a second data point

The old posterior becomes our new prior

```{r }
grid <- grid %>% 
  mutate(likelihood = dnorm(true_data[2], possible_mean, 2),
         posterior = likelihood * posterior,
         posterior = posterior / sum(posterior))
```

---
# Plot

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```


---
# Observe a third data point

```{r }
grid <- grid %>% 
  mutate(likelihood = dnorm(true_data[3], possible_mean, 2),
         posterior = likelihood * posterior,
         posterior = posterior / sum(posterior))
```

---
# Plot

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```

---
# All the data

```{r }
grid <- grid %>% 
  mutate(prior = dnorm(grid$possible_mean, mean = 2, sd = 3),
         prior = prior / sum(prior),
         posterior = prior) # best guess before seeing data

for(i in seq_along(true_data)) {
  grid <- grid %>% 
    mutate(likelihood = dnorm(true_data[i], possible_mean, 2),
           posterior = likelihood * posterior,
           posterior = posterior / sum(posterior))
}
```

---

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```

---
# Posterior
* We can summarize our posterior distribution
 
* This is a fundamental difference between Bayesian & frequentist approaches

  + In Bayes, our data is assumed fixed, our parameters random
  
  + In frequentist, our data is assumed random, our parameters fixed


---
# Most likely?

```{r }
grid %>% 
  filter(posterior == max(posterior))
```

---
# Sampling
* Now that we have a posterior distribution, we can sample from it to help us with inference

* Each possible mean should be sampled in accordance with its probability specified by the posterior.

--
* Let's draw 10,000 samples

```{r }
posterior_samples <- sample(grid$possible_mean, 
                            size = 10000,
                            replace = TRUE,
                            prob = grid$posterior)
```
---
# Inference
First, let's plot the samples

--
```{r }
ggplot(data.frame(sample = posterior_samples), aes(sample)) +
  geom_histogram(bins = 100)
```


---
# Central tendency

```{r }
mean(posterior_samples)
median(posterior_samples)
```

--
## Spread

```{r }
sd(posterior_samples)
```


---
# Credible intervals
Let's compute an 80% credible interval

```{r }
tibble(posterior_samples) %>% 
  summarize(ci_80 = quantile(posterior_samples, c(0.1, 0.9)))
```

--
## What's the chance the "true" mean is less than 4.8?

```{r }
sum(posterior_samples < 4.8) / length(posterior_samples) * 100
```

---
# Ranges

What's the probability the "true" mean is between 5.2 and 5.5?

--
```{r }
sum(posterior_samples >= 5.2 & posterior_samples <= 5.5) / 
  length(posterior_samples) * 100
```

--
Greater than 4.5?

```{r }
sum(posterior_samples > 4.5) / length(posterior_samples) * 100
```

--
Note this is much more natural than frequentist statistics


---
# Change our prior
Let's try again with a tighter prior

```{r }
grid <- grid %>% 
  mutate(prior = dnorm(grid$possible_mean, mean = 2, sd = 0.1),
         prior = prior / sum(prior),
         posterior = prior) # best guess before seeing data

for(i in seq_along(true_data)) {
  grid <- grid %>% 
    mutate(likelihood = dnorm(true_data[i], possible_mean, 2),
           posterior = likelihood * posterior,
           posterior = posterior / sum(posterior))
}
```

---

```{r fig.height = 5}
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```

```{r }
grid %>% 
  filter(posterior == max(posterior))
```

---
# More data
Same thing, but this time with tons of data

---

```{r }
true_data <- rnorm(5000, 5, 1)
grid <- grid %>% 
  mutate(prior = dnorm(grid$possible_mean, mean = 2, sd = 0.1),
         prior = prior / sum(prior),
         posterior = prior) # best guess before seeing data

for(i in seq_along(true_data)) {
  grid <- grid %>% 
    mutate(likelihood = dnorm(true_data[i], possible_mean, 2),
           posterior = likelihood * posterior,
           posterior = posterior / sum(posterior))
}
```

---

```{r fig.height = 4.5}
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```

```{r }
grid %>% 
  filter(posterior == max(posterior))
```

---
# Taking a step back
* The purpose of the prior is to include *what you already know* into your analysis

* The strength of your prior should depend on your prior research

* Larger samples will overwhelm priors quicker, particularly if they are diffuse

* Think through the lens of updating your prior beliefs

* This whole framework is quite different, but also gives us a lot of advantages in terms of probability interpretation, as we'll see

---
class: inverse-blue middle
# Bayes for regression

---
# More complicated
* Remember our posterior is defined by


$$
\text{posterior} = \frac{ \text{likelihood} \times \text{prior}}{\text{average likelihood}}
$$

--
When we just had a single parameter to estimate, $\mu$, this was tractable with grid search.


--
With even simple linear regression, however, we have three parameters: $\alpha$, $\beta$, and $\sigma$


--
Our Bayesian model then becomes considerably more complicated:

$$
P(\alpha, \beta, \sigma \mid x) = \frac{ P(x \mid \alpha, \beta, \sigma) \, P(\alpha, \beta, \sigma)}{\iiint \, P(x \mid \alpha, \beta, \sigma) \, P(\alpha, \beta, \sigma) \,d\alpha \,d\beta \,d\sigma}
$$


---
# Estimation
Rather than trying to compute the integrals, we *simulate* observations from the joint posterior distribution.


--
This sounds a bit like magic - how do we do this?


--
Multiple different algorithms, but all use some form of Markov-Chain Monte-Carlo sampling

---
# Conceptually

* Imagine the posterior as a hill

* We start with the parameters set to random numbers

  + Estimate the posterior with this values (our spot on the hill)

* Use information from the prior sample to determine whether and how to change the current parameter values 

* Try to "walk" around in a way to a complete "picture" of the hill from the samples

* Use these samples as your posterior distribution

---
# Metropolis-Hastings
We will use is called the Metropolis-Hastings algorithm:

* Compute a candidate "step" for the parameters

* Calculate an acceptance ratio $\alpha = f(x')/f(x_t)$. This will fall between 0 and 1.

* Generate number, $u$, from a random uniform distribution between 0 and 1 

  + if $u \leq \alpha$, accept the candidate

  + if $u \geq \alpha$, reject the candidate


--
Complicated, but conceptually we're trying to sample the joint posterior distribution in a way that conforms with the probability density of the posterior (i.e., the shape)

---
# Script
* The `mh-alg.R` script works through the Metropolis-Hastings algorithm to get samples from the joint posterior of a simple linear regression model.

* The data are simulated, so we know the true values

* It's complicated, and not required at all, but it's there for you if you want more info


---
class: inverse-green middle
# Next time
Continue discussing Bayes - more emphasis on model results & plotting

Fit and interpret multilevel logistic regression models
