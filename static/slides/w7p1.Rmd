---
title: "An introduction to Bayesian estimation"
author: "Daniel Anderson "
date: "Week 7"
output:
  xaringan::moon_reader:
    css: ["default", "new.css"]
    lib_dir: libs
    nature:
      navigation:
        scroll: false
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "https://platform.twitter.com/widgets.js"
    includes:
      in_header: "load-feather.html"
---

```{r include = FALSE}
source(here::here("static", "slides", "slide-setup.R"))
xaringanExtra::use_clipboard()
library(tidyverse)
theme_set(theme_minimal(25))
knitr::opts_chunk$set(fig.width = 13, message = FALSE)
update_geom_defaults('path', list(size = 2))
update_geom_defaults('point', list(size = 5))
update_geom_defaults('text', list(size = 9))
```

`r setup("w7p1")`

---
# Agenda

* Some equation practice

* Introduce Bayes theorem

* Go through an example with estimating a mean

* Discuss Bayes in the context of regression modeling

* Implementation with multilevel models in R with [**{brms}**](https://github.com/paul-buerkner/brms)

* Model diagnostics and checking for convergence

---
class: inverse-red middle
# Equation practice

---
# The data
From an example in the Mplus manual. I made up the column names. 

`r countdown::countdown(1, seconds = 30)`

```{r }
mplus_d <- read_csv(here::here("data", "mplus920.csv"))
mplus_d
```


---
# Model 1
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
library(lme4)
library(equatiomatic)

m1 <- lmer(score ~ 1 + (1|distid),
           data = mplus_d)

extract_eq(m1)
```


--
```{r eval = FALSE}
lmer(score ~ 1 + (1|distid), data = mplus_d)
```

---
# Model 2
### Fit the following model

`r countdown::countdown(1)`

```{r echo = FALSE, message = FALSE}
m2 <- lmer(score ~ baseline + (1|schid) + (1|distid),
           data = mplus_d)

extract_eq(m2)
```


--
```{r eval = FALSE}
lmer(score ~ baseline + (1|schid) + (1|distid),
     data = mplus_d)
```

---
# Model 3
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m3 <- lmer(score ~ baseline * dist_ses + (baseline|schid) + (1|distid),
           data = mplus_d)

extract_eq(m3)
```


--
```{r eval = FALSE}
lmer(score ~ baseline * dist_ses + 
       (baseline|schid) + (1|distid),
     data = mplus_d)
```

---
# Model 4
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m4 <- lmer(score ~ baseline + sch_treatment + dist_ses + 
             (baseline|schid) + (1|distid),
           data = mplus_d)

extract_eq(m4)
```


--
```{r eval = FALSE}
lmer(score ~ baseline + sch_treatment + dist_ses + 
       (baseline|schid) + (1|distid),
     data = mplus_d)
```


---
# Model 5
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m5 <- lmer(score ~ baseline * sch_treatment + dist_ses + 
             (baseline|schid) + (sch_treatment|distid),
           data = mplus_d)

extract_eq(m5)
```


--
```{r eval = FALSE}
lmer(score ~ baseline * sch_treatment + dist_ses + 
       (baseline|schid) + (sch_treatment|distid),
     data = mplus_d)
```


---
# Model 6
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m6 <- lmer(score ~ baseline * sch_treatment + dist_ses + 
             (baseline|schid) + (baseline * sch_treatment||distid),
           data = mplus_d)

extract_eq(m6, font_size = "small")
```


--
```{r eval = FALSE}
lmer(score ~ baseline * sch_treatment + dist_ses + 
       (baseline|schid) + 
       (baseline * sch_treatment||distid),
           data = mplus_d)
```


---
# Final one
### Fit the following model

`r countdown::countdown(1, seconds = 30)`

```{r echo = FALSE, message = FALSE}
m7 <- lmer(score ~ baseline * sch_treatment * dist_ses + 
             (baseline|schid) + (baseline |distid),
           data = mplus_d)

extract_eq(m7, font_size = "scriptsize")
```


--
```{r eval = FALSE}
lmer(score ~ baseline * sch_treatment + dist_ses + 
             (baseline|schid) + (baseline * sch_treatment||distid),
           data = mplus_d)
```


---
class: inverse-blue middle
# Bayes



---
# A disclaimer
* There is **no** chance we'll really be able to do Bayes justice in this class

* The hope for today is that you'll get an introduction

* By the end you should be able to fit the models you already can, but in a Bayes framework

* Hopefully you also recognize the tradeoffs, and potential extensions

---
class: inverse-blue middle
# Bayes theorem

---
# In equation form
You'll see this presented many different ways, perhaps mostly commonly as

$$
p(B \mid A) = \frac{ p(A \mid B) \times p(B)}{p(A)}
$$
where $\mid$ is read as "given" and $p$ is the probability

--

I prefer to give $A$ and $B$ more meaningful names

--

$$
p(\text{prior} \mid \text{data}) = \frac{ p(\text{data} \mid \text{prior}) \times p(\text{prior})}{\text{data}}
$$

---
# A real example
Classifying a student with a learning disability. We want to know 

$$
p(\text{LD} \mid \text{Test}_p) = \frac{ p(\text{Test}_p \mid \text{LD}) \times p(\text{LD})}{\text{Test}_p}
$$
--
Notice, this means we need to know:

--

* True positive rate of the test, $p(\text{Test}_p \mid \text{LD})$


--

* Base rate for learning disabilities, $p(\text{LD})$


--
* Base rate for testing positive, $\text{Test}_p$

---
# Estimating
If we have these things, we can estimate the probability that a student has a learning disability, given a positive test.


--
## Let's assume: 
* $p(\text{Test}_p \mid \text{LD}) = 0.90$

* $p(\text{LD}) = 0.10$

* $\text{Test}_p = 0.20$

---

$$
p(\text{LD} \mid \text{Test}_p) = \frac{ .90 \times .10}{.20}
$$


--
$$
p(\text{LD} \mid \text{Test}_p) = 0.45
$$


--
A bit less than you might have expected? Probability is hard...


--
When we see things like "90% true positive rate" we want to interpret it as $p(\text{LD} \mid \text{Test}_p)$, when it's actually $p(\text{Test}_p \mid \text{LD})$

---
# Pieces
If we know all the pieces, we can estimate Bayes theorem directly. 


--
![](https://media2.giphy.com/media/2ZVrNVOtaM2q1zluYs/giphy.gif)

Unfortunately this is almost never the case...

---
# Alternative view

$$
\text{updated beliefs} = \frac{\text{likelihood of data} \times \text{prior information}}{\text{average likelihood}}
$$

--
How do we calculate the likelihood of the data? We have to assume some distribution.

---
# Example with IQ

.footnote[This example borrowed from [TJ Mahr](https://cdn.rawgit.com/tjmahr/Psych710_BayesLecture/55f446a0/bayes_slides.html)]

```{r }
#install.packages("carData")
iqs <- carData::Burt$IQbio
iqs
```

--
IQ scores are generally assumed to be generated from a distribution that looks like this:

$$
IQ_i \sim N(100, 15)
$$

--
```{r echo = FALSE, fig.height = 3}
ggplot(data.frame(x = c(60, 140)), aes(x)) +
  stat_function(fun = ~dnorm(., 100, 15))
```

---
# Likelihood
What's the likelihood of a score of 80, assuming this distribution?

--
```{r echo = FALSE, fig.height = 6}
ggplot(data.frame(x = c(60, 140)), aes(x)) +
  stat_function(fun = ~dnorm(., 100, 15)) +
  geom_point(aes(y = y),
             data.frame(x = 80, y = dnorm(80, 100, 15)),
             color = "magenta") +
  geom_segment(x = 80, xend = 80, y = 0, yend = dnorm(80, 100, 15),
               linetype = "dashed",
               color = "magenta") +
  geom_segment(x = -Inf, xend = 80, 
               y = dnorm(80, 100, 15), yend = dnorm(80, 100, 15),
               linetype = "dashed",
               color = "magenta")
```

--

```{r }
dnorm(80, mean = 100, sd = 15)
```

---
# Likelihood of the data
We sum the likelihood to get the overall likelihood of the data. However, this leads to very small numbers. Computationally, it's easier to sum the *log* of these likelihoods.

--
```{r }
dnorm(iqs, mean = 100, sd = 15, log = TRUE)
```

--
```{r }
sum(dnorm(iqs, mean = 100, sd = 15, log = TRUE))
```

---
# Alternative distributions

What if we assumed the data were generated from an alternative distribution, say $IQ_i \sim N(115, 5)$?

--
```{r }
sum(dnorm(iqs, mean = 115, sd = 5, log = TRUE))
```

--
The value is *much* lower. In most models, we are estimating $\mu$ and $\sigma$, and trying to find values that *maximize* the sum of the log likelihoods.

---
# Visually

The real data generating distribution

```{r echo = FALSE}
iq_likelihood <- data.frame(x = iqs, y = dnorm(iqs, 100, 15))

ggplot(data.frame(x = c(60, 140)), aes(x)) +
  stat_function(fun = ~dnorm(., 100, 15)) +
  geom_point(aes(y = y),
             iq_likelihood,
             color = "magenta") +
  geom_segment(aes(x = x, xend = x, y = 0, yend = y),
               iq_likelihood,
               linetype = "dashed",
               color = "magenta")
```

---
# Visually

The poorly fitting one

```{r echo = FALSE}
iq_likelihood2 <- data.frame(x = iqs, y = dnorm(iqs, 120, 5))

ggplot(data.frame(x = c(60, 140)), aes(x)) +
  stat_function(fun = ~dnorm(., 120, 5)) +
  geom_point(aes(y = y),
             iq_likelihood2,
             color = "magenta") +
  geom_segment(aes(x = x, xend = x, y = 0, yend = y),
               iq_likelihood2,
               linetype = "dashed",
               color = "magenta")
```

---
# Non-Bayesian
In a frequentist regression model, we would find parameters that *maximize* the likelihood. Note - the distributional mean is often conditional.


--
This is part of why I've come to prefer notation that emphasizes the data generating process. 

---
# Example
I know we've talked about this before, but a simple linear regression model like this

```{r }
m <- lm(IQbio ~ class, data = carData::Burt)
```

--
is generally displayed like this


```{r echo = FALSE}
equatiomatic::extract_eq(m, font_size = "normalsize")
```


--
But we could display the same thing like this
$$
\begin{align}
\operatorname{IQbio} &\sim N(\widehat{\mu}, \widehat{\sigma}) \\
\widehat{\mu} = \alpha &+ \beta_{1}(\operatorname{class}_{\operatorname{low}}) + \beta_{2}(\operatorname{class}_{\operatorname{medium}})
\end{align}
$$

---
class: inverse-red middle

# Priors

---
# Bayesian posterior

$$
\text{posterior} = \frac{ \text{likelihood} \times \text{prior}}{\text{average likelihood}}
$$


--
The above is how we estimate with Bayes. 


--
In words, it states that our updated beliefs (posterior) depend on the evidence from our data (likelihood) and our prior knowledge/conceptions/information (prior).


--
Our prior will shift in accordance with the evidence from the data

---
# Basic example
Let's walk through a basic example where we're just estimating a mean. We'll assume we somehow magically know the variance. Please follow along.


--
First, generate some data

```{r }
set.seed(123)
true_data <- rnorm(50, 5, 1)
```

---
# Grid search
We're now going to specify a grid of possible means for our data. Let's search anywhere from -3 to 12 in 0.1 intervals.

--
```{r }
grid <- tibble(possible_mean = seq(-3, 12, 0.1))
```

--

Next, we'll specify a *prior distribution*. That is - how likely do we *think* each of these possible means are?


--
Let's say our best guess is $mu = 2$. Values on either side of $2$ should be less likely.  

--
```{r }
prior <- dnorm(grid$possible_mean, mean = 2, sd = 1)
```

---
# Plot our prior

```{r }
grid %>% 
  mutate(prior = prior) %>% 
  ggplot(aes(possible_mean, prior)) +
  geom_line()
```

Note that the *strength* of our prior depends on the standard deviation

This would be our best guess as to where the data would fall *before* observing the data.

---
# Look at other priors

```{r fig.height = 6}
grid %>% 
  mutate(prior1 = dnorm(possible_mean, mean = 2, sd = 1),
         prior2 = dnorm(possible_mean, mean = 2, sd = 2),
         prior3 = dnorm(possible_mean, mean = 2, sd = 3)) %>% 
  ggplot(aes(possible_mean)) +
  geom_line(aes(y = prior1)) + 
  geom_line(aes(y = prior2), color = "cornflowerblue") + 
  geom_line(aes(y = prior3), color = "firebrick")  
```

---
# Set prior
* Let's go with a fairly conservative prior, with $\mu = 2, \sigma = 3$.

* We also need to normalize it so the probability sums to 1.0

--
```{r }
grid <- grid %>% 
  mutate(prior = dnorm(possible_mean, mean = 2, sd = 3),
         prior = prior / sum(prior)) # normalize
```


---
# Observe 1 data point
```{r }
grid <- grid %>% 
  mutate(likelihood = dnorm(true_data[1], possible_mean, 2))
grid
```

---
# Compute posterior

```{r }
grid <- grid %>% 
  mutate(posterior = likelihood * prior,
         posterior = posterior / sum(posterior)) # normalize
```

---
# Plot

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```


---
# Observe a second data point

The old posterior becomes our new prior

```{r }
grid <- grid %>% 
  mutate(likelihood = dnorm(true_data[2], possible_mean, 2),
         posterior = likelihood * posterior,
         posterior = posterior / sum(posterior))
```

---
# Plot

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```


---
# Observe a third data point

```{r }
grid <- grid %>% 
  mutate(likelihood = dnorm(true_data[3], possible_mean, 2),
         posterior = likelihood * posterior,
         posterior = posterior / sum(posterior))
```

---
# Plot

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```

---
# All the data

```{r }
grid <- grid %>% 
  mutate(prior = dnorm(grid$possible_mean, mean = 2, sd = 3),
         prior = prior / sum(prior),
         posterior = prior) # best guess before seeing data

for(i in seq_along(true_data)) {
  grid <- grid %>% 
    mutate(likelihood = dnorm(true_data[i], possible_mean, 2),
           posterior = likelihood * posterior,
           posterior = posterior / sum(posterior))
}
```

---

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```

---
# Posterior
* We can summarize our posterior distribution
 
* This is a fundamental difference between Bayesian & frequentist approaches

  + In Bayes, our data is assumed fixed, our parameters random
  
  + In frequentist, our data is assumed random, our parameters fixed


--
Most likely?

```{r }
grid %>% 
  filter(posterior == max(posterior))
```

---
# Sampling
* Now that we have a posterior distribution, we can sample from it to help us with inference

* Each possible mean should be sampled in accordance with its probability specified by the posterior.

--
* Let's draw 10,000 samples

```{r }
posterior_samples <- sample(grid$possible_mean, 
                            size = 10000,
                            replace = TRUE,
                            prob = grid$posterior)
```
---
# Inference
First, let's plot the samples

--
```{r }
ggplot(data.frame(sample = posterior_samples), aes(sample)) +
  geom_histogram(bins = 100)
```


---
# Central tendency

```{r }
mean(posterior_samples)
median(posterior_samples)
```

--
## Spread

```{r }
sd(posterior_samples)
```


---
# Credible intervals
Let's compute an 80% credible interval

```{r }
tibble(posterior_samples) %>% 
  summarize(ci_80 = quantile(posterior_samples, c(0.1, 0.9)))
```

--
## What's the chance the "true" mean is less than 4.8?

```{r }
sum(posterior_samples < 4.8) / length(posterior_samples) * 100
```

---
# Ranges

What's the probability the "true" mean is between 5.2 and 5.5?

--
```{r }
sum(posterior_samples >= 5.2 & posterior_samples <= 5.5) / 
  length(posterior_samples) * 100
```

--
Greater than 4.5?

```{r }
sum(posterior_samples > 4.5) / length(posterior_samples) * 100
```

--
Note this is much more natural than frequentist statistics


---
# Change our prior
Let's try again with a tighter prior

```{r }
grid <- grid %>% 
  mutate(prior = dnorm(grid$possible_mean, mean = 2, sd = 0.1),
         prior = prior / sum(prior),
         posterior = prior) # best guess before seeing data

for(i in seq_along(true_data)) {
  grid <- grid %>% 
    mutate(likelihood = dnorm(true_data[i], possible_mean, 2),
           posterior = likelihood * posterior,
           posterior = posterior / sum(posterior))
}
```

---

```{r fig.height = 5}
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```

```{r }
grid %>% 
  filter(posterior == max(posterior))
```

---
# More data
Same thing, but this time with tons of data

---

```{r }
true_data <- rnorm(5000, 5, 1)
grid <- grid %>% 
  mutate(prior = dnorm(grid$possible_mean, mean = 2, sd = 0.1),
         prior = prior / sum(prior),
         posterior = prior) # best guess before seeing data

for(i in seq_along(true_data)) {
  grid <- grid %>% 
    mutate(likelihood = dnorm(true_data[i], possible_mean, 2),
           posterior = likelihood * posterior,
           posterior = posterior / sum(posterior))
}
```

---

```{r }
grid %>% 
  pivot_longer(-possible_mean) %>% 
ggplot(aes(possible_mean, value)) +
  geom_line(aes(color = name))
```

```{r }
grid %>% 
  filter(posterior == max(posterior))
```

---
# Taking a step back
* The purpose of the prior is to include *what you already know* into your analysis

* The strength of your prior should depend on your prior research

* Larger samples will overwhelm priors quicker, particularly if they are diffuse

* Think through the lens of updating your prior beliefs

* This whole framework is quite different, but also gives us a lot of advantages in terms of probability interpretation, as we'll see

---
class: inverse-blue middle
# Bayes for regression

---
class: inverse-blue middle

# Implementation with {brms}

.center[
![](https://github.com/paul-buerkner/brms/raw/master/man/figures/brms.png)
]

---
# What is it?
* **b**ayesian **r**egression **m**odeling with **s**tan

* Uses [stan](https://mc-stan.org/) as the model backend - basically writes the model code for you then sends it to stan

* Allows model syntax similar to **lme4** 

* Simple specification of priors - defaults are flat

* Provides many methods for post-model fitting inference

---
# Fit a basic model
Let's start with the default (uninformative) priors, and fit a standard, simple-linear regression model

```{r }
library(brms)
sleep_m0 <- brm(Reaction ~ Days, data = lme4::sleepstudy)
```

---
# Model summary

```{r }
summary(sleep_m0)
```

---
# View fixed effect
Let's look at our estimated relation between `Days` and `Reaction`

--
```{r }
conditional_effects(sleep_m0)
```

---
# Wrong model
Of course, this is the wrong model, we have a multilevel structure

```{r echo = FALSE, message = FALSE}
ggplot(lme4::sleepstudy, aes(Days, Reaction)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~Subject) +
  theme_minimal(15)
```

---
# Multilevel model
Notice the syntax is essentially equivalent to **lme4**

```{r eval = FALSE}
sleep_m1 <- brm(Reaction ~ Days + (Days | Subject), data = lme4::sleepstudy)
summary(sleep_m1)
```

```{r include = FALSE}
sleep_m1 <- brm(Reaction ~ Days + (Days | Subject), data = lme4::sleepstudy)
```

```{r echo = FALSE}
summary(sleep_m1)
```

---
# Fixed effect
The uncertainty has increased

```{r }
conditional_effects(sleep_m1)
```

---
# Checking your model

```{r }
pp_check(sleep_m1)
```

---
# More checks

```{r }
plot(sleep_m1)
```

---
# Even more

```{r eval = FALSE}
launch_shinystan(sleep_m1)
```

---
# Another model

```{r eval = FALSE}
kidney_m0 <- brm(time ~ age + sex, data = kidney)
pp_check(kidney_m0, type = "ecdf_overlay")
```

```{r include = FALSE}
kidney_m0 <- brm(time ~ age + sex, data = kidney)
```

```{r echo = FALSE}
pp_check(kidney_m0, type = "ecdf_overlay")
```

---
# Fixing this
We need to change the assumptions of our model - specifically that the outcome is not normally distributed

--
Maybe Poisson?

```{r eval = FALSE}
kidney_m1 <- brm(time ~ age + sex, data = kidney, family = poisson())
```

```{r include = FALSE}
kidney_m1 <- brm(time ~ age + sex, data = kidney, family = poisson())
```

---
# Nope

```{r }
pp_check(kidney_m1, type = "ecdf_overlay")
```


---
# Gamma w/log link
```{r eval = FALSE}
kidney_m2 <- brm(time ~ age + sex, data = kidney, family = Gamma("log"))
pp_check(kidney_m2, type = "ecdf_overlay")
```

```{r include = FALSE}
kidney_m2 <- brm(time ~ age + sex, data = kidney, family = Gamma("log"))
```

```{r echo = FALSE}
pp_check(kidney_m2, type = "ecdf_overlay")
```


---
# Specifying priors
Let's sample from *only* our priors to see what kind of predictions we get.

Here, we're specifying that our beta coefficient prior is $\beta \sim N(0, 0.5)$ 
  
```{r eval = FALSE}
kidney_m3 <- brm(
  time ~ age + sex, 
  data = kidney,
  family = Gamma("log"),
  prior = prior(normal(0, 0.5), class = "b"),
  sample_prior = "only"
)
```

```{r include = FALSE}
kidney_m3 <- brm(
  time ~ age + sex, 
  data = kidney,
  family = Gamma("log"),
  prior = prior(normal(0, 0.5), class = "b"),
  sample_prior = "only"
)
```

---
```{r }
kidney_m3
```

---
# Prior predictions
Random sample of 100 points

```{r echo = FALSE}
kidney %>% 
  tidybayes::add_fitted_draws(kidney_m3) %>% 
  ungroup() %>% 
  sample_n(100) %>% 
  ggplot(aes(time, .value)) +
  geom_point() +
  facet_wrap(~sex) +
  scale_y_log10(labels = scales::comma)
```

---
# Why?
It seemed like our prior was fairly tight


--
The exploding prior happens because of the log transformation

* Age is coded in years

* Imagine a coef of 1 (2 standard deviations above our prior)

* Prediction for a 25 year old would be exp(25) = `r round(exp(25), 3)`

---
# A note on prior specifications
* It's hard

* I don't have a ton of good advice

* Be particularly careful when you're using distributions that have anything other than an identity link (e.g., log link, as we are here)

---
# One more model
Let's fit a model we've fit previously


--
In Week 4, we fit this model

```{r }
library(lme4)
popular <- read_csv(here::here("data", "popularity.csv"))
m_lmer <- lmer(popular ~ extrav + (extrav|class), popular,
               control = lmerControl(optimizer = "bobyqa"))
```

--
Try fitting the same model with **{brms}** with the default, diffuse priors

`r countdown::countdown(2)`

---
# Bayesian verision

```{r include = FALSE}
m_brms <- brm(popular ~ extrav + (extrav|class), popular)
```

```{r eval = FALSE}
m_brms <- brm(popular ~ extrav + (extrav|class), popular)
```

---
# lme4 model
```{r }
arm::display(m_lmer)
```


---
# brms model

```{r }
m_brms
```

---
# Plotting the Bayes fit

```{r fig.height = 5}
tibble(extrav = 1:10, class = 0) %>% 
  tidybayes::add_fitted_draws(m_brms, 
                              allow_new_levels = TRUE, 
                              n = 100) %>% 
  ggplot(aes(extrav, .value)) +
  geom_line(aes(group = .draw), size = 0.1)
```

---
# Add in raw data
```{r fig.height = 5}
library(tidybayes)
tibble(extrav = 1:10, class = 0) %>% 
  add_fitted_draws(m_brms, allow_new_levels = TRUE, n = 100) %>% 
  ggplot(aes(extrav, .value)) +
  geom_point(aes(extrav, popular), data = popular,
             color = "gray70") + #<<
  geom_line(aes(group = .draw), size = 0.1)
```

---
# Speed
We'll never reach the `lme4::lmer()` speeds, but we can make it faster.

* Parallelize (not always as effective as you might hope)

* Use the cmdstanr backend
  + This requires a little bit of additional work, but is probably worth it if you're
  fitting bigger models.

```{r }
install.packages(
  "cmdstanr",
  repos = c("https://mc-stan.org/r-packages/", getOption("repos"))
)
```

---
# Timings
I'm not evaluating the below, but the timings were 114.368 seconds and 87.383 seconds, respectively.

```{r eval = FALSE}
library(tictoc)

tic()
m_brms <- brm(popular ~ extrav + (extrav|class), popular)
toc()

tic()
m_brms2 <- brm(popular ~ extrav + (extrav|class), popular,
               backend = "cmdstanr")#<<
toc()
```

---
class: inverse-red middle
# Wrapping up


---
# Advantages to Bayes
* Opportunity to incorporate prior knowledge into the modeling process (you don't really *have* to - could just set wide priors)

* Natural interpretation of uncertainty

* Can often allow you to estimate models that are difficult if not impossible with frequentist methods


--

## Disadvatages

* Generally going to be slower in implementation

* You may run into pushback from others - particularly with respect to prior

---
# Notes on the posterioir
* The posterior is the distribution of the parameters, given the data

* You can think of it as the distribution of what we don't know, but are interested in (the model parameters), given what we know or have observed (the data), and our prior beliefs

* Gives a complete picture of parameter uncertainty

* We can do lots of things with the posterior that is hard to get otherwise

* Next time, we'll discuss how missing values can be treated as unknown variables (parameters) in the model, and imputed from the posterior

---
class: inverse-green middle
# Next time
Continue discussing Bayes - more emphasis on model results & plotting

Fit and interpret multilevel logistic regression models
